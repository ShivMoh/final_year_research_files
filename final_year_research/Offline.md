For example, the Llama series of open source models is a great contender for utilising LLMs locally, as it is completely open sourced to the public for use. The most recent suite of Llama3 models, are capable of contending with models of similar sizes. The Meta Llama 70B parameters have shown comparable features to ChatGPT3.5 and Claude. In additon, its 8B parameter models are also comparable to models of similar sizes such as mistral and Gemma. Furthermore, there are also releases of smaller models made for on device computing such as mobile and edge devices, namely Llama3.2 1B and Llama.2 3B parameter models. And that does not exclude the previous suite of Llama2 models which are still suitable candidates for the task of text generation.

In additon, there also exist other open source models based on the same architecture as Llama, such as the Mistral series of models and TinyLlama, a ongoing project of recreating Llama with only a subset of the available data. So it is to say, there are avenues available for applying open source models on local hardware to offset the costs and privacy concerns of utilising LLMs in ITS. These concerns that which were mentioned or observed with projects such as MWPTutor and Ruffle&Riley.

